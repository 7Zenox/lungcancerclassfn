{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7ZBf13t3a0H"
      },
      "source": [
        "## Setup\n",
        "NOTE: this notebook is more advanced than the ViT one because it uses tensorflow data objects which are smarter and easier to work with. This took some time, so I can also do this for ViT later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Xme_bKsT3a0H"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-03 13:09:55.781195: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/home/andyd/miniconda3/envs/nlp/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdEjsXIj3a0I"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lfKoxyXD8wWU"
      },
      "outputs": [],
      "source": [
        "# loading all images\n",
        "images = []\n",
        "labels = []\n",
        "root = './dataset/merged/'\n",
        "for folder in os.listdir(root):\n",
        "    for image in os.listdir(os.path.join(root, folder)):\n",
        "        images.append(cv2.imread(os.path.join(root, folder, image)))\n",
        "        labels.append(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "PJKivc99Jf51",
        "outputId": "828ac8d7-d109-4aad-e95e-819332abf855"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0_Bengin cases</th>\n",
              "      <th>0_Malignant cases</th>\n",
              "      <th>0_Normal cases</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0_Bengin cases  0_Malignant cases  0_Normal cases\n",
              "0               1                  0               0\n",
              "1               1                  0               0\n",
              "2               1                  0               0\n",
              "3               1                  0               0\n",
              "4               1                  0               0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_normal = pd.DataFrame(labels)\n",
        "y_normal[0].unique()\n",
        "y = pd.get_dummies(y_normal)\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "the dataset creation cell threw a warning aboout ragged sequences here, so i'm gonna detour here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{(512, 801, 3), (512, 623, 3), (404, 511, 3), (331, 506, 3)}\n",
            "Number of irregular images: 61\n"
          ]
        }
      ],
      "source": [
        "# verify sizes of all images.\n",
        "resolution = set()\n",
        "count = 0\n",
        "for image in images:\n",
        "    if image.shape != (512, 512, 3):\n",
        "        resolution.add(image.shape)\n",
        "        count += 1\n",
        "print(str(resolution) + '\\n' + f\"Number of irregular images: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#FIXTHIS 61 images have irregular resolutions. Removing them for now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "filtimg = list()\n",
        "\n",
        "for idx in range(len(images)):\n",
        "    if images[idx].shape == (512, 512, 3):\n",
        "        filtimg.append(images[idx])\n",
        "    else:\n",
        "        y.drop(idx, axis='rows', inplace=True)\n",
        "\n",
        "if (len(images) - len(filtimg)) == 61:\n",
        "    images = filtimg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = np.array(images)\n",
        "\n",
        "dataset.shape[0] == y.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1036, 3)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4TTaKhW3a0I",
        "outputId": "eb042114-9ef8-4b51-f365-0c71329b2851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (777, 512, 512, 3) - y_train shape: (777, 3)\n",
            "x_test shape: (259, 512, 512, 3) - y_test shape: (259, 3)\n"
          ]
        }
      ],
      "source": [
        "num_classes = np.unique(y).shape[0]\n",
        "input_shape = (512, 512, 3)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(dataset, y, test_size = 0.25,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameter initialisation and Dataset finalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KVy2KjSQ3a0J"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "num_epochs = 15\n",
        "image_size = 56  # We'll resize input images to this size\n",
        "patch_size = 8  # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using tensorflow dataset objects moving forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1097 files belonging to 3 classes.\n",
            "Using 878 files for training.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-03 13:10:22.671442: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-08-03 13:10:22.720760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-08-03 13:10:22.720809: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-08-03 13:10:22.723341: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-08-03 13:10:22.723385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-08-03 13:10:22.723407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-08-03 13:10:23.473737: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-08-03 13:10:23.473814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-08-03 13:10:23.473847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
            "2023-08-03 13:10:23.473895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2023-08-03 13:10:23.473929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5905 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 Super, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "# importing the training split\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  root,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1097 files belonging to 3 classes.\n",
            "Using 219 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# importing the validation split\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  root,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Bengin cases', 'Malignant cases', 'Normal cases']\n"
          ]
        }
      ],
      "source": [
        "# testing for class names presence\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 180, 180, 3)\n",
            "(32,)\n"
          ]
        }
      ],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'tensorflow' has no attribute 'AUTOTUNE'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m   ds \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mprefetch(buffer_size\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mAUTOTUNE)\n\u001b[1;32m      6\u001b[0m   \u001b[39mreturn\u001b[39;00m ds\n\u001b[0;32m----> 8\u001b[0m train_ds \u001b[39m=\u001b[39m configure_for_performance(train_ds)\n\u001b[1;32m      9\u001b[0m val_ds \u001b[39m=\u001b[39m configure_for_performance(val_ds)\n",
            "Cell \u001b[0;32mIn[14], line 5\u001b[0m, in \u001b[0;36mconfigure_for_performance\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m      3\u001b[0m ds \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mshuffle(buffer_size\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m)\n\u001b[1;32m      4\u001b[0m ds \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mbatch(batch_size)\n\u001b[0;32m----> 5\u001b[0m ds \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mprefetch(buffer_size\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39;49mAUTOTUNE)\n\u001b[1;32m      6\u001b[0m \u001b[39mreturn\u001b[39;00m ds\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'AUTOTUNE'"
          ]
        }
      ],
      "source": [
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=tf.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
        "  label = label_batch[i]\n",
        "  plt.title(class_names[label])\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "28/28 [==============================] - 3s 51ms/step - loss: 0.8981 - accuracy: 0.5843 - val_loss: 0.8463 - val_accuracy: 0.5936\n",
            "Epoch 2/15\n",
            "28/28 [==============================] - 1s 32ms/step - loss: 0.6247 - accuracy: 0.7517 - val_loss: 0.5932 - val_accuracy: 0.7306\n",
            "Epoch 3/15\n",
            "28/28 [==============================] - 1s 27ms/step - loss: 0.3450 - accuracy: 0.8770 - val_loss: 0.3198 - val_accuracy: 0.8584\n",
            "Epoch 4/15\n",
            "28/28 [==============================] - 1s 27ms/step - loss: 0.1718 - accuracy: 0.9431 - val_loss: 0.3221 - val_accuracy: 0.8813\n",
            "Epoch 5/15\n",
            "28/28 [==============================] - 1s 27ms/step - loss: 0.1036 - accuracy: 0.9681 - val_loss: 0.1140 - val_accuracy: 0.9680\n",
            "Epoch 6/15\n",
            "28/28 [==============================] - 1s 26ms/step - loss: 0.0335 - accuracy: 0.9920 - val_loss: 0.0567 - val_accuracy: 0.9772\n",
            "Epoch 7/15\n",
            "28/28 [==============================] - 1s 26ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0551 - val_accuracy: 0.9863\n",
            "Epoch 8/15\n",
            "28/28 [==============================] - 1s 27ms/step - loss: 0.0137 - accuracy: 0.9977 - val_loss: 0.0666 - val_accuracy: 0.9817\n",
            "Epoch 9/15\n",
            "28/28 [==============================] - 1s 25ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.2229 - val_accuracy: 0.9452\n",
            "Epoch 10/15\n",
            "28/28 [==============================] - 1s 29ms/step - loss: 0.0199 - accuracy: 0.9954 - val_loss: 0.0754 - val_accuracy: 0.9817\n",
            "Epoch 11/15\n",
            "28/28 [==============================] - 1s 29ms/step - loss: 0.0096 - accuracy: 0.9989 - val_loss: 0.1190 - val_accuracy: 0.9680\n",
            "Epoch 12/15\n",
            "28/28 [==============================] - 1s 27ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.1556 - val_accuracy: 0.9680\n",
            "Epoch 13/15\n",
            "28/28 [==============================] - 1s 27ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.1526 - val_accuracy: 0.9589\n",
            "Epoch 14/15\n",
            "28/28 [==============================] - 1s 32ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.1016 - val_accuracy: 0.9726\n",
            "Epoch 15/15\n",
            "28/28 [==============================] - 1s 35ms/step - loss: 0.0225 - accuracy: 0.9943 - val_loss: 0.0979 - val_accuracy: 0.9817\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f94684f2890>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes = 3\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Rescaling(1./255),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "fit = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=15,\n",
        "  callbacks=[tensorboard_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0979 - accuracy: 0.9817\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.09788387268781662, 0.9817351698875427]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(val_ds)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "environment": {
      "name": "tf2-gpu.2-4.m61",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
