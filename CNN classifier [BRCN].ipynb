{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7ZBf13t3a0H"
      },
      "source": [
        "## Setup\n",
        "NOTE: this notebook is more advanced than the ViT one because it uses tensorflow data objects which are smarter and easier to work with. This took some time, so I can also do this for ViT later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Xme_bKsT3a0H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_addons as tfa\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdEjsXIj3a0I"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lfKoxyXD8wWU"
      },
      "outputs": [],
      "source": [
        "# loading all images\n",
        "images = []\n",
        "labels = []\n",
        "root = './dataset/breast-cancer/'\n",
        "for folder in os.listdir(root):\n",
        "    for image in os.listdir(os.path.join(root, folder)):\n",
        "        images.append(cv2.imread(os.path.join(root, folder, image)))\n",
        "        labels.append(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "PJKivc99Jf51",
        "outputId": "828ac8d7-d109-4aad-e95e-819332abf855"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0_benign</th>\n",
              "      <th>0_malignant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0_benign  0_malignant\n",
              "0         1            0\n",
              "1         1            0\n",
              "2         1            0\n",
              "3         1            0\n",
              "4         1            0"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_normal = pd.DataFrame(labels)\n",
        "y_normal[0].unique()\n",
        "y = pd.get_dummies(y_normal)\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameter initialisation and Dataset finalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KVy2KjSQ3a0J"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "batch_size = 32\n",
        "img_height = 90\n",
        "img_width = 90\n",
        "num_epochs = 15\n",
        "image_size = 56  # We'll resize input images to this size\n",
        "patch_size = 8  # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 8\n",
        "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using tensorflow dataset objects moving forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 250 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# importing the training split\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        root,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 250 files belonging to 2 classes.\n",
            "Using 50 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# importing the validation split\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  root,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'DirectoryIterator' object has no attribute 'class_names'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# testing for class names presence\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m class_names \u001b[39m=\u001b[39m train_generator\u001b[39m.\u001b[39;49mclass_names\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(class_names)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'class_names'"
          ]
        }
      ],
      "source": [
        "# testing for class names presence\n",
        "class_names = train_generator.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 150, 150, 3)\n",
            "(32,)\n"
          ]
        }
      ],
      "source": [
        "for image_batch, labels_batch in train_generator:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "  return ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_batch, label_batch = next(iter(train_generator))\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
        "  label = label_batch[i]\n",
        "  plt.title(label_batch[i])\n",
        "  plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_22434/4145167468.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  fit = model.fit_generator(\n",
            "2023-08-03 19:08:46.522680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
            "2023-08-03 19:08:47.671674: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-03 19:08:49.052691: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a24054420 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-08-03 19:08:49.052762: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 Super, Compute Capability 7.5\n",
            "2023-08-03 19:08:49.057373: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-08-03 19:08:49.313649: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2023-08-03 19:08:49.386101: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'tensorflow.compat.v2.summary' has no attribute 'scalar'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[44], line 21\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m      4\u001b[0m  \u001b[39m# tf.keras.layers.Rescaling(1./255),\u001b[39;00m\n\u001b[1;32m      5\u001b[0m   tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv2D(\u001b[39m32\u001b[39m, \u001b[39m3\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m   tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(num_classes, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m ])\n\u001b[1;32m     16\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     17\u001b[0m   optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m   loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(),\n\u001b[1;32m     19\u001b[0m   metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 21\u001b[0m fit \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[1;32m     22\u001b[0m   train_generator,\n\u001b[1;32m     23\u001b[0m   validation_data\u001b[39m=\u001b[39;49mval_ds,\n\u001b[1;32m     24\u001b[0m   epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,\n\u001b[1;32m     25\u001b[0m   callbacks\u001b[39m=\u001b[39;49m[tensorboard_callback]\n\u001b[1;32m     26\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/keras/src/engine/training.py:2810\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2798\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2799\u001b[0m \n\u001b[1;32m   2800\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2801\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2802\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2803\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2804\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2805\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2806\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2807\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2808\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2809\u001b[0m )\n\u001b[0;32m-> 2810\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   2811\u001b[0m     generator,\n\u001b[1;32m   2812\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   2813\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   2814\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2815\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   2816\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   2817\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   2818\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   2819\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   2820\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2821\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2822\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2823\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   2824\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   2825\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/keras/src/callbacks.py:2824\u001b[0m, in \u001b[0;36mTensorBoard.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   2822\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(logs, \u001b[39mdict\u001b[39m):\n\u001b[1;32m   2823\u001b[0m     \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m logs\u001b[39m.\u001b[39mitems():\n\u001b[0;32m-> 2824\u001b[0m         tf\u001b[39m.\u001b[39;49msummary\u001b[39m.\u001b[39;49mscalar(\u001b[39m\"\u001b[39m\u001b[39mbatch_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name, value, step\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_step)\n\u001b[1;32m   2826\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_trace:\n\u001b[1;32m   2827\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.compat.v2.summary' has no attribute 'scalar'"
          ]
        }
      ],
      "source": [
        "num_classes = 2\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        " # tf.keras.layers.Rescaling(1./255),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "fit = model.fit_generator(\n",
        "  train_generator,\n",
        "  validation_data=val_ds,\n",
        "  epochs=15,\n",
        "  callbacks=[tensorboard_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 9ms/step - loss: 0.2834 - accuracy: 0.9452\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.2833906412124634, 0.9452054500579834]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(val_ds, callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "for x, y in val_ds.unbatch():\n",
        "    images.append(x)\n",
        "    labels.append(np.array(y).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = np.array(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = (model.predict(test)).argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 2, 2, 2, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 1, 1, 1, 2, 1, 1, 0,\n",
              "       1, 0, 2, 2, 1, 2, 1, 0, 1, 2, 1, 0, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2,\n",
              "       2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 0, 2, 1, 0, 1, 0, 0, 1, 1, 2, 2, 1,\n",
              "       1, 1, 0, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 0, 1, 2,\n",
              "       1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 0, 1, 1, 1, 2, 1, 0,\n",
              "       1, 2, 1, 2, 1, 2, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2,\n",
              "       1, 1, 2, 2, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 2, 2, 2,\n",
              "       2, 0, 2, 2, 1, 2, 1, 2, 0, 2, 2, 2, 1, 0, 1, 1, 1, 2, 0, 1, 2, 1,\n",
              "       0, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 2, 1,\n",
              "       1, 1, 1, 2, 0, 1, 2, 2, 1, 0, 1, 1, 1, 2, 1, 2, 0, 0, 1, 2, 1])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============TEST RESULTS============\n",
            "Confusion Matrix\n",
            "[[ 23   0   2]\n",
            " [  7 112   0]\n",
            " [  3   0  72]]\n",
            "\n",
            "Classification Report\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   Bengin cases       0.70      0.92      0.79        25\n",
            "Malignant cases       1.00      0.94      0.97       119\n",
            "   Normal cases       0.97      0.96      0.97        75\n",
            "\n",
            "       accuracy                           0.95       219\n",
            "      macro avg       0.89      0.94      0.91       219\n",
            "   weighted avg       0.96      0.95      0.95       219\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(\"==============TEST RESULTS============\")\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(labels, y_pred))\n",
        "print('\\nClassification Report')\n",
        "print(classification_report(labels, y_pred, target_names=val_ds.class_names))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "environment": {
      "name": "tf2-gpu.2-4.m61",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
